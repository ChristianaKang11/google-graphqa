{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import graph_text_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_custom_name_dict():\n",
    "    \"\"\"Create a custom name dictionary for a car market graph.\"\"\"\n",
    "    return {\n",
    "        0: 'Toyota',\n",
    "        1: 'Ford',\n",
    "        2: 'Tesla',\n",
    "        3: 'Camry',\n",
    "        4: 'Mustang',\n",
    "        5: 'Model S',\n",
    "        6: 'Dealership A',\n",
    "        7: 'Dealership B'\n",
    "    }\n",
    "    \n",
    "name_dict = create_custom_name_dict()  \n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(range(8))  \n",
    "# Adding edges (manufacturer to car models, models to dealerships)\n",
    "G.add_edges_from([(0, 3), (1, 4), (2, 5)])  # Manufacturers to models\n",
    "G.add_edges_from([(3, 6), (4, 6), (5, 7)])  # Models to dealerships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G describes a friendship graph among nodes Toyota, Ford, Tesla, Camry, Mustang, Model S, Dealership A, and Dealership B.\n",
      "We have the following edges in G:\n",
      "Toyota and Camry are friends.\n",
      "Ford and Mustang are friends.\n",
      "Tesla and Model S are friends.\n",
      "Camry and Dealership A are friends.\n",
      "Mustang and Dealership A are friends.\n",
      "Model S and Dealership B are friends.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Based on the paper, friendship encoder performs the best for zero-shot \n",
    "encoded_graph = graph_text_encoder.friendship_encoder(G, name_dict)\n",
    "print(encoded_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kang\\Desktop\\berkeley\\qlay\\graphqa\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "prompt_template = \"\"\"\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "prompt = PromptTemplate(input_variables=[\"context\", \"question\"], template=prompt_template)\n",
    "llm_chain=LLMChain(llm=OpenAI(api_key=api_key), prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_car_market_question(question):\n",
    "    prompt_variables = {\n",
    "        \"context\": encoded_graph,\n",
    "        \"question\": question\n",
    "    }\n",
    "    answer = llm_chain.run(prompt_variables)\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kang\\Desktop\\berkeley\\qlay\\graphqa\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:  Model S\n"
     ]
    }
   ],
   "source": [
    "question = \"Which cars are sold at Dealership B?\" #From paper, we know friendship encoding should performs well on edge existence\n",
    "answer = ask_car_market_question(question)\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a question for cycle check, based on the paper, friendship encoding should performs well on cycle check under the zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:  Yes, the following route forms a closed loop: Toyota - Camry - Dealership A - Mustang - Ford - Tesla - Model S - Dealership B - Toyota.\n"
     ]
    }
   ],
   "source": [
    "question = \"Considering all connections between manufacturers, their cars, and dealerships, can you identify a route that forms a closed loop starting and ending at the same point without visiting any node twice?\"\n",
    "answer = ask_car_market_question(question)\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
